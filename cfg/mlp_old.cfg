## __trainer__
@trainer
	@@target
		## active
		@@active
			model=mlp
			@@mlp
				min_samples=10
				batch_size=100
				device=gpu
				epochs=1000
				profile=0
				init_type=1
				@@opt
					type=adam
					lr=0.001				
				@@@net
					hidden_sizes=[24, 24]
					activation_types=['relu',]
				@@@
			@@@
		@@@
		## lost
		@@lost
			model=mlp
			verbose=0
			@@mlp
				@@opt
					type=adam
					lr=0.001
				@@@
				min_samples=5
				batch_size=100
				device=gpu
				epochs=1000
				profile=0
				accumulative=1
				init_type=1
				pause_for_debug=0
				@@net
					hidden_sizes=[24, 48, 24]
					activation_types=['relu',]
				@@@
			@@@
